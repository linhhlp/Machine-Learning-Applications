{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20f9fcf9",
   "metadata": {},
   "source": [
    "# Adding Context to Model\n",
    "\n",
    "`Context` is very important. For example, on weekdays people tend to watch short clips, and at the weekend people can watch a full-length movie because they have free time. On Amazon, there are probably products that benefit from time.\n",
    "\n",
    "In this example, we will predict based on the time when a user rated a product and see how it impacts on overall prediction accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85eb3bcb",
   "metadata": {},
   "source": [
    "## Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4a57465",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "comp_dir = Path('../input/amazon-product-reviews')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7326046",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import tensorflow as tf\n",
    "from datetime import datetime,timedelta\n",
    "\n",
    "import tensorflow_recommenders as tfrs\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") \n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e90d11a",
   "metadata": {},
   "source": [
    "## Importing & Reducing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a89f4f27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>productId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A20XXTXWF2TCPY</td>\n",
       "      <td>0972683275</td>\n",
       "      <td>5</td>\n",
       "      <td>1405123200</td>\n",
       "      <td>2014-07-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A2IDCSC6NVONIZ</td>\n",
       "      <td>0972683275</td>\n",
       "      <td>5</td>\n",
       "      <td>1367280000</td>\n",
       "      <td>2013-04-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A3BMUBUC1N77U8</td>\n",
       "      <td>0972683275</td>\n",
       "      <td>4</td>\n",
       "      <td>1385164800</td>\n",
       "      <td>2013-11-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A3UOSOCRKS3WIH</td>\n",
       "      <td>0972683275</td>\n",
       "      <td>5</td>\n",
       "      <td>1368316800</td>\n",
       "      <td>2013-05-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A2HLNXOYLMERTC</td>\n",
       "      <td>0972683275</td>\n",
       "      <td>5</td>\n",
       "      <td>1397606400</td>\n",
       "      <td>2014-04-16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           userId   productId  rating   timestamp   datetime\n",
       "0  A20XXTXWF2TCPY  0972683275       5  1405123200 2014-07-12\n",
       "1  A2IDCSC6NVONIZ  0972683275       5  1367280000 2013-04-30\n",
       "2  A3BMUBUC1N77U8  0972683275       4  1385164800 2013-11-23\n",
       "3  A3UOSOCRKS3WIH  0972683275       5  1368316800 2013-05-12\n",
       "4  A2HLNXOYLMERTC  0972683275       5  1397606400 2014-04-16"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "electronics_data=pd.read_csv(comp_dir / \"ratings_Electronics (1).csv\", dtype={'rating': 'int8'}\n",
    "                             ,names=['userId', 'productId','rating','timestamp'], index_col=None, header=0)\n",
    "electronics_data[\"datetime\"] = pd.to_datetime(electronics_data.timestamp, unit=\"s\")\n",
    "############ Only count Rating after 2012 ##################\n",
    "cutoff_year        = 2012  \n",
    "electronics_data   = electronics_data.loc[electronics_data[\"datetime\"].dt.year > cutoff_year]  #Reducing data\n",
    "############ products which received >= 50 ##################\n",
    "cutoff_no_rat = 50    ## Only count products which received more than or equal 50\n",
    "electronics_data   = electronics_data.loc[electronics_data.groupby(\"productId\")[\"rating\"].transform('count').ge(\n",
    "                                            cutoff_no_rat)].reset_index(drop=True)\n",
    "############ users who rated >= 5 ##################\n",
    "cutoff_no_user    = 5    ## Only count users who rated more than or equal 5\n",
    "electronics_data  = electronics_data.loc[electronics_data.groupby(\"userId\")[\"rating\"].transform('count').ge(\n",
    "                                            cutoff_no_user)].reset_index(drop=True)\n",
    "electronics_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "243ca749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Rating: 437,330\n",
      "Number of Users: 58,013\n",
      "Number of Products: 13,824\n"
     ]
    }
   ],
   "source": [
    "userIds           = electronics_data.userId.unique()\n",
    "productIds        = electronics_data.productId.unique()\n",
    "unique_productIds = productIds\n",
    "unique_userIds    = userIds\n",
    "total_ratings     = len(electronics_data.index)\n",
    "\n",
    "print(\"Number of Rating: {:,}\".  format(total_ratings) )\n",
    "print(\"Number of Users: {:,}\".   format(len(userIds) ) )\n",
    "print(\"Number of Products: {:,}\".format(len(productIds)  ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e96f4dac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Convert Pandas to TF Dataset\n",
    "ratings    = tf.data.Dataset.from_tensor_slices({\"userId\":tf.cast( electronics_data.userId.values  ,tf.string),\n",
    "                                                \"productId\":tf.cast( electronics_data.productId.values,tf.string),\n",
    "                                                \"rating\":tf.cast( electronics_data.rating.values  ,tf.int8),\n",
    "                                                \"timestamp\":tf.cast( electronics_data.rating.values  ,tf.int64,) } )\n",
    "productIds = tf.data.Dataset.from_tensor_slices(productIds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16773f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-process timestamp\n",
    "timestamps    = electronics_data.timestamp.values\n",
    "max_timestamp = timestamps.max()\n",
    "min_timestamp = timestamps.min()\n",
    "\n",
    "timestamp_buckets = np.linspace( min_timestamp, max_timestamp, num=1000,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1cde07c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for model fitting and testing\n",
    "# For perfect shuffling, a `buffer size` greater than or equal to the full size of the dataset is required.\n",
    "tf.random.set_seed(123) # set seed so we re-produce the same results very time running\n",
    "shuffled = ratings.shuffle(10_000_000, seed=123, reshuffle_each_iteration=False)\n",
    "\n",
    "train = shuffled.take( int(total_ratings*0.8) )\n",
    "test  = shuffled.skip(int(total_ratings*0.8)).take(int(total_ratings*0.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d100fbc1",
   "metadata": {},
   "source": [
    "## Building Context Model\n",
    "\n",
    "To learn more, read from [Tensorflow Recommenders website](https://www.tensorflow.org/recommenders/examples/featurization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a18d6ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserModel(tf.keras.Model):\n",
    "    def __init__(self, use_timestamps):\n",
    "        super().__init__()\n",
    "        self._use_timestamps = use_timestamps\n",
    "        \n",
    "        self.user_embeddings = tf.keras.Sequential([\n",
    "                                    tf.keras.layers.StringLookup(\n",
    "                                        vocabulary=unique_userIds, mask_token=None),\n",
    "                                        # add addional embedding to account for unknow tokens\n",
    "                                    tf.keras.layers.Embedding(len(unique_userIds)+1, 32)\n",
    "                                    ])\n",
    "        if use_timestamps:\n",
    "            self.timestamp_embedding = tf.keras.Sequential([\n",
    "                                    tf.keras.layers.Discretization( timestamp_buckets.tolist() ),\n",
    "                                        # add addional embedding to account for unknow tokens\n",
    "                                    tf.keras.layers.Embedding(len(timestamp_buckets)+1, 32)\n",
    "                                    ])\n",
    "            self.normalized_timestamp = tf.keras.layers.experimental.preprocessing.Normalization(axis=None)\n",
    "            self.normalized_timestamp.adapt(timestamps)\n",
    "    \n",
    "    def call(self,inputs):\n",
    "        if not self._use_timestamps:\n",
    "            return self.user_embeddings( inputs[\"userId\"])\n",
    "        return tf.concat([\n",
    "            self.user_embeddings     ( inputs[\"userId\"]),\n",
    "            self.timestamp_embedding( inputs[\"timestamp\"]),\n",
    "            tf.reshape(self.normalized_timestamp(inputs[\"timestamp\"]), (-1, 1)),\n",
    "            ], axis=1)\n",
    "    \n",
    "\n",
    "class ProductModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        max_tokens = 100_000\n",
    "\n",
    "        self.title_embedding = tf.keras.Sequential([\n",
    "                                    tf.keras.layers.StringLookup(\n",
    "                                        vocabulary=unique_productIds, mask_token=None),\n",
    "                                        # add addional embedding to account for unknow tokens\n",
    "                                    tf.keras.layers.Embedding(len(unique_productIds)+1, 32)\n",
    "                                    ])\n",
    "        self.title_vectorizer = tf.keras.layers.TextVectorization(max_tokens=max_tokens)\n",
    "        self.title_text_embedding = tf.keras.Sequential([\n",
    "                                        self.title_vectorizer,\n",
    "                                        tf.keras.layers.Embedding(max_tokens, 32, mask_zero=True),\n",
    "                                        tf.keras.layers.GlobalAveragePooling1D(),\n",
    "                                        ])\n",
    "        self.title_vectorizer.adapt(productIds)\n",
    "    \n",
    "    def call(self,titles):\n",
    "        return tf.concat([\n",
    "            self.title_embedding     ( titles),\n",
    "            self.title_text_embedding( titles),\n",
    "            ], axis=1)\n",
    "    \n",
    "# Build a model.\n",
    "class amazonModel(tfrs.models.Model):\n",
    "\n",
    "    def __init__(self, use_timestamps):\n",
    "        super().__init__()\n",
    "        self.query_model     = tf.keras.Sequential([ UserModel(use_timestamps),\n",
    "                                                 tf.keras.layers.Dense(32) ])\n",
    "        self.candidate_model = tf.keras.Sequential([ ProductModel(),\n",
    "                                                 tf.keras.layers.Dense(32) ])\n",
    "        self.task            = tfrs.tasks.Retrieval( metrics = tfrs.metrics.FactorizedTopK(\n",
    "                                                        candidates=productIds.batch(1024).map(self.candidate_model) )\n",
    "                                                    )\n",
    "            \n",
    "    def compute_loss(self, features, training=False):\n",
    "        query_embeddings = self.query_model({ \"userId\":features[\"userId\"], \"timestamp\":features[\"timestamp\"] }  )\n",
    "        product_embeddings = self.candidate_model(features[\"productId\"])\n",
    "        return self.task( query_embeddings, product_embeddings)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a582e0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = amazonModel(use_timestamps=False)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad( learning_rate=0.1 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "240bd999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'userId': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=string>, 'timestamp': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=int64>}\n",
      "Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'userId': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=string>, 'timestamp': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=int64>}\n",
      "Consider rewriting this model with the Functional API.\n"
     ]
    }
   ],
   "source": [
    "cached_train = train.batch(4096).cache()\n",
    "cached_test  = test.batch(2048).cache()\n",
    "\n",
    "model.fit(cached_train, epochs=50, verbose=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "959bdb9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'userId': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=string>, 'timestamp': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=int64>}\n",
      "Consider rewriting this model with the Functional API.\n",
      "86/86 [==============================] - 33s 374ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0556 - factorized_top_k/top_5_categorical_accuracy: 0.3207 - factorized_top_k/top_10_categorical_accuracy: 0.5033 - factorized_top_k/top_50_categorical_accuracy: 0.8013 - factorized_top_k/top_100_categorical_accuracy: 0.8638 - loss: 11908.7259 - regularization_loss: 0.0000e+00 - total_loss: 11908.7259\n",
      "43/43 [==============================] - 10s 216ms/step - factorized_top_k/top_1_categorical_accuracy: 1.0290e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0013 - factorized_top_k/top_10_categorical_accuracy: 0.0040 - factorized_top_k/top_50_categorical_accuracy: 0.0321 - factorized_top_k/top_100_categorical_accuracy: 0.0610 - loss: 39207.9011 - regularization_loss: 0.0000e+00 - total_loss: 39207.9011\n",
      "Top-100 accuracy (train): 0.86.\n",
      "Top-100 accuracy (test): 0.06.\n"
     ]
    }
   ],
   "source": [
    "train_accuracy = model.evaluate( cached_train, return_dict=True)[\"factorized_top_k/top_100_categorical_accuracy\"];\n",
    "test_accuracy  = model.evaluate( cached_test,  return_dict=True)[\"factorized_top_k/top_100_categorical_accuracy\"];\n",
    "\n",
    "print(f\"Top-100 accuracy (train): {train_accuracy:.2f}.\")\n",
    "print(f\"Top-100 accuracy (test): {test_accuracy:.2f}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6429949b",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_model = amazonModel(use_timestamps=True)\n",
    "time_model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "53885c70",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'userId': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=string>, 'timestamp': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=int64>}\n",
      "Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'userId': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=string>, 'timestamp': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=int64>}\n",
      "Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'userId': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=string>, 'timestamp': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=int64>}\n",
      "Consider rewriting this model with the Functional API.\n",
      "86/86 [==============================] - 32s 370ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0537 - factorized_top_k/top_5_categorical_accuracy: 0.2954 - factorized_top_k/top_10_categorical_accuracy: 0.4560 - factorized_top_k/top_50_categorical_accuracy: 0.7338 - factorized_top_k/top_100_categorical_accuracy: 0.8087 - loss: 13492.8269 - regularization_loss: 0.0000e+00 - total_loss: 13492.8269\n",
      "43/43 [==============================] - 9s 210ms/step - factorized_top_k/top_1_categorical_accuracy: 5.7165e-05 - factorized_top_k/top_5_categorical_accuracy: 0.0010 - factorized_top_k/top_10_categorical_accuracy: 0.0035 - factorized_top_k/top_50_categorical_accuracy: 0.0301 - factorized_top_k/top_100_categorical_accuracy: 0.0599 - loss: 34022.8991 - regularization_loss: 0.0000e+00 - total_loss: 34022.8991\n",
      "Top-100 accuracy (train): 0.81.\n",
      "Top-100 accuracy (test): 0.06.\n"
     ]
    }
   ],
   "source": [
    "time_model.fit(cached_train, epochs=50, verbose=False);\n",
    "\n",
    "train_accuracy = time_model.evaluate(cached_train, return_dict=True)[\"factorized_top_k/top_100_categorical_accuracy\"];\n",
    "test_accuracy  = time_model.evaluate(cached_test, return_dict=True)[\"factorized_top_k/top_100_categorical_accuracy\"];\n",
    "\n",
    "print(f\"Top-100 accuracy (train): {train_accuracy:.2f}.\")\n",
    "print(f\"Top-100 accuracy (test): {test_accuracy:.2f}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f863208",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this example, `timestamp` has a negligible impact on the predictions for a special type of product. We would love to have more information on the products or users to improve the accuracy of the predictive model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec496853",
   "metadata": {},
   "source": [
    "# Higher Density of Data\n",
    "\n",
    "In the previous dataset, the number of Ratings is 437,330 but the number of Users is 58,013, which means each user only rated 8 products on average. The number is too small in comparison to the number of Products: 13,824, which is around 0.06%. After training the model, the accuracy of the model is about 0.06 or 6% (it could be improved a bit higher with more iterations), which is about hundreds of times of rated product ratio.\n",
    "\n",
    "Let's reduce the size of the rating data to filter users who rated much more products. The more user rated, the more information we have about users, hence, the higher precision of the modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a15082fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Rating: 37,356\n",
      "Number of Users: 1,320\n",
      "Number of Products: 8,634\n"
     ]
    }
   ],
   "source": [
    "############ users who rated >= 5 ##################\n",
    "cutoff_no_user    = 20    ## Only count users who rated more than or equal 5\n",
    "electronics_data  = electronics_data.loc[electronics_data.groupby(\"userId\")[\"rating\"].transform('count').ge(\n",
    "                                            cutoff_no_user)].reset_index(drop=True)\n",
    "userIds           = electronics_data.userId.unique()\n",
    "productIds        = electronics_data.productId.unique()\n",
    "unique_productIds = productIds\n",
    "unique_userIds    = userIds\n",
    "total_ratings     = len(electronics_data.index)\n",
    "\n",
    "print(\"Number of Rating: {:,}\".  format(total_ratings) )\n",
    "print(\"Number of Users: {:,}\".   format(len(userIds) ) )\n",
    "print(\"Number of Products: {:,}\".format(len(productIds)  ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7b739ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Pandas to TF Dataset\n",
    "ratings    = tf.data.Dataset.from_tensor_slices({\"userId\":tf.cast( electronics_data.userId.values  ,tf.string),\n",
    "                                                \"productId\":tf.cast( electronics_data.productId.values,tf.string),\n",
    "                                                \"rating\":tf.cast( electronics_data.rating.values  ,tf.int8),\n",
    "                                                \"timestamp\":tf.cast( electronics_data.rating.values  ,tf.int64,) } )\n",
    "productIds = tf.data.Dataset.from_tensor_slices(productIds)\n",
    "# Pre-process timestamp\n",
    "timestamps    = electronics_data.timestamp.values\n",
    "max_timestamp = timestamps.max()\n",
    "min_timestamp = timestamps.min()\n",
    "\n",
    "timestamp_buckets = np.linspace( min_timestamp, max_timestamp, num=1000,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cbe907a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(123) # set seed so we re-produce the same results very time running\n",
    "shuffled = ratings.shuffle(10_000_000, seed=123, reshuffle_each_iteration=False)\n",
    "\n",
    "train = shuffled.take( int(total_ratings*0.8) )\n",
    "test  = shuffled.skip(int(total_ratings*0.8)).take(int(total_ratings*0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4b6b5f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = amazonModel(use_timestamps=False)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad( learning_rate=0.1 ))\n",
    "cached_train = train.batch(2096).cache()\n",
    "cached_test  = test.batch(1048).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "317aeb56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'userId': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=string>, 'timestamp': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=int64>}\n",
      "Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'userId': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=string>, 'timestamp': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=int64>}\n",
      "Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'userId': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=string>, 'timestamp': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=int64>}\n",
      "Consider rewriting this model with the Functional API.\n",
      "15/15 [==============================] - 3s 160ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0297 - factorized_top_k/top_5_categorical_accuracy: 0.2038 - factorized_top_k/top_10_categorical_accuracy: 0.4110 - factorized_top_k/top_50_categorical_accuracy: 0.8963 - factorized_top_k/top_100_categorical_accuracy: 0.9500 - loss: 5698.3648 - regularization_loss: 0.0000e+00 - total_loss: 5698.3648\n",
      "8/8 [==============================] - 1s 113ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 1.3385e-04 - factorized_top_k/top_50_categorical_accuracy: 0.0269 - factorized_top_k/top_100_categorical_accuracy: 0.0705 - loss: 11963.3041 - regularization_loss: 0.0000e+00 - total_loss: 11963.3041\n",
      "Top-100 accuracy (train): 0.95.\n",
      "Top-100 accuracy (test): 0.07.\n"
     ]
    }
   ],
   "source": [
    "model.fit(cached_train, epochs=50, verbose=False);\n",
    "train_accuracy = model.evaluate( cached_train, return_dict=True)[\"factorized_top_k/top_100_categorical_accuracy\"];\n",
    "test_accuracy  = model.evaluate( cached_test,  return_dict=True)[\"factorized_top_k/top_100_categorical_accuracy\"];\n",
    "print(f\"Top-100 accuracy (train): {train_accuracy:.2f}.\")\n",
    "print(f\"Top-100 accuracy (test): {test_accuracy:.2f}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57a42e8",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Although adding timestamp does not improve the predictions based on Amazon review, we have a demo of how to implement it to a model. It will be more interesting if there is more available information on different aspects of products or users."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
