{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dfd53c25",
   "metadata": {},
   "source": [
    "# Convert Text to Vector and Vector Search"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "13536e6e",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "The Program is divided into several sections:\n",
    "\n",
    "1.  [Convert Movies' Plots to Vectors](Step1_converter-full-movies.ipynb)\n",
    "2.  [Do Vector Search with DataStax on Cassandra](Step2_Vector-Search-DataStax.ipynb)\n",
    "3.  [Prompt Engineering](Step3_Prompt-Engineering.ipynb)\n",
    "4.  [Vector Search with Cluster](Step4_Cluster-Vector-Search.ipynb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a0f1e467",
   "metadata": {},
   "source": [
    "## Tune Generative AI with Vector Search\n",
    "\n",
    "Generative AI is an AI model/technology that produces (generates) content including text, graphics, audio, and videos.\n",
    "\n",
    "Generative AI is good at generating general information, but it does not have all the information, especially, the knowledge in a specific domain (Domain Knowledge). Therefore, we will input the specialized information (in the format of a list of movies), and ask the Generative AI to select from this data. \n",
    "\n",
    "What applications are available when using Vector Search and Prompt Engineering in Language Models (LLMs)? \n",
    "\n",
    "0. Content-based retrieval: Based on the vector (embedding from the user's input), the system will identify and retrieve similar and related contents. For example, finding similar images, videos, and songs.\n",
    "\n",
    "1. Recommendation: Based on the current viewing item, suggest items similar or relevant. For example, products on shopping, movie, or song while watching or listening.\n",
    "\n",
    "2. Semantic Search: Vector Search helps to find relevant information in a specific domain. For example, when a customer looks for an item, based on the search query, the system will return relevant items that better understand keywords because the meaning and context of the keywords are captured in the embedding.\n",
    "\n",
    "3. Question answering: Vector Search helps to find relevant information in a specific domain, then Generative AI can use this information to generate accurate information. For example, a customer asks for a specific car model, User Manuals, Operating Instructions, or client inquiries about the company's policies. This is the case of Prompt Engineering.\n",
    "\n",
    "4. Accelerator: Language Models (LMs) are very expensive when running due to neural network structure in deep learning. The Vector Search can shortlist the items which are related to the current situations, therefore, reducing the resources LMs use to lower the cost of operating. This is crucial in a high level of usage/traffic. We can cache the results from Vector Search to ensure the flexibility and dynamics of LMs."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0675ea04",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "In this project, we will use a dataset of movies with plots. The original dataset is on https://www.kaggle.com/datasets/gabrieltardochi/wikipedia-movie-plots-with-plot-summaries\n",
    "\n",
    "The plots were scraped from Wikipedia by [jrobischon](https://www.kaggle.com/datasets/jrobischon/wikipedia-movie-plots) and then summarized by [gabrieltardochi](https://www.kaggle.com/datasets/gabrieltardochi/wikipedia-movie-plots-with-plot-summaries) using [DistilBART-CNN-12-6 model](https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
    "\n",
    "There are two plots, one is full and the other is shortened. I used CO.HERE AI to vectorize them. The processed dataset was published on [Kaggle](https://www.kaggle.com/datasets/linhhlp/35k-movies-with-embedded-plots-to-vectors): https://www.kaggle.com/datasets/linhhlp/35k-movies-with-embedded-plots-to-vectors\n",
    "\n",
    "The detail of the process is in [the next Chapter](Step1_converter-full-movies.ipynb)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c024c6ea",
   "metadata": {},
   "source": [
    "## Prompt Engineering\n",
    "\n",
    "To achieve the best results which are the closest to the query, we use a Generate Model with Prompt Engineering to generate the best candidates.\n",
    "\n",
    "![full_diagram.png](images/full_diagram_system_design.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9eee35f5",
   "metadata": {},
   "source": [
    "## Vector Search with Cluster\n",
    "\n",
    "what we can recommend to a user after he has watched multiple items/movies/products recently?\n",
    "\n",
    "For example, the user wants to search for a movie based on a list of movies that they watched in the past. Or we want to suggest products based on what they shopped for in the past."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cedda9b1",
   "metadata": {},
   "source": [
    "## Find-Movies service \n",
    "\n",
    "An demo of the project is deployed at https://find-movies.com/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9482f801",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2d62a598",
   "metadata": {},
   "source": [
    "### Clone or download the repo\n",
    "First get local copies of the program:\n",
    "\n",
    "https://github.com/linhhlp/Machine-Learning-Applications\n",
    "\n",
    "### Install the dependencies\n",
    "\n",
    "This program has been developed and tested on:\n",
    "\n",
    "* python 3.9.10\n",
    "* pandas 1.4.1\n",
    "* notebook 6.4.8\n",
    "* cassandra-driver\n",
    "\n",
    "The quickest, easiest way to install is to use Anaconda:\n",
    "\n",
    "#### Installing with anaconda\n",
    "\n",
    "Install [anaconda](http://anaconda.com/downloads)\n",
    "\n",
    "The quickest, easiest way to install dependencies is to use the command line to create an environment and install the packages:\n",
    "\n",
    "```bash\n",
    "$ conda env create\n",
    "$ source activate new_env\n",
    "```\n",
    "\n",
    "Install the remaining dependencies with:\n",
    "\n",
    "```bash\n",
    "conda install tensorflow sklearn seaborn\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5d792096",
   "metadata": {},
   "source": [
    "## References:\n",
    "\n",
    "I would like to thank this people and other sources I have learned to complete this comprehensive model.\n",
    "\n",
    "1. DataStax for free of Cassandra and Vector Search (still in public preview).\n",
    "\n",
    "2. CO.HERE AI for free API"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
