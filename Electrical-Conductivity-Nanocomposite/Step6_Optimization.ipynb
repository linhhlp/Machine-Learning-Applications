{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a114cbc7",
   "metadata": {},
   "source": [
    "# Optimizing Model\n",
    "\n",
    "\n",
    "## List of optimization parameters we could try\n",
    "\n",
    "* `Optimizer` function / algorithms could be fine tuned to produce the best fit\n",
    "* `Loss` function / algorithms could be replaced with more suitable one. Because the `conductivity` highly diverges.\n",
    "* Other subtle parameters: `learning_rate`, `decay`, `epochs`, `batch_size`, neuron `layers` and `activation` function.\n",
    "* `Scalers`: Both X and Y values are strongly unrelated due to various types of fillers (and polymers).\n",
    "* Hardware accelation: By default, it utilizes which are available in system. In my case, it automatically runs on GPU NVIDIA GeForce RTX 2060"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873acb16",
   "metadata": {},
   "source": [
    "## `epochs`\n",
    "\n",
    "As the dataset includes multiple ranges of magnitude-order, the iterations of training are large and depending on configuration of optimizing parameters, the number of `epochs` can go up to thoudsands.\n",
    "\n",
    "Although more iteration could produce better fitting, but will be overfitting if the number is too high. We need to watch how the losses of training data and testing data behave. \n",
    "\n",
    "## `batch_size`\n",
    "\n",
    "Too large of a batch size will lead to poor generalization\n",
    "\n",
    "Smaller batch sizes could shown to have faster convergence to “good” solutions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e72ea9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98b706d",
   "metadata": {},
   "source": [
    "## GPU performance\n",
    "\n",
    "Use tf.config.list_physical_devices('GPU') to confirm that TensorFlow is using the GPU.\n",
    "\n",
    "### Use less memory\n",
    "\n",
    "Using `tf.config.set_visible_devices` to restrict TensorFlow to only allocate 1GB of memory on the first GPU\n",
    "```python\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    tf.config.set_logical_device_configuration( gpus[0],\n",
    "        [tf.config.LogicalDeviceConfiguration(memory_limit=1024)])\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Virtual devices must be set before GPUs have been initialized\n",
    "    print(e)\n",
    "```\n",
    "### Reference sources \n",
    "* [Use a GPU](https://www.tensorflow.org/guide/gpu)\n",
    "* [`tf.config.experimental`](https://www.tensorflow.org/api_docs/python/tf/config/experimental)\n",
    "* [TensorFlow Profiler](https://www.tensorflow.org/guide/gpu_performance_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d5bf7f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.experimental.list_physical_devices(device_type=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ee9696a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd78a89d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    tf.config.set_logical_device_configuration( gpus[0],\n",
    "        [tf.config.LogicalDeviceConfiguration(memory_limit=1024)])\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Virtual devices must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63ff4af",
   "metadata": {},
   "source": [
    "### Issue with Windows 10\n",
    "\n",
    "There is an issue when using GPU but nothing is calculated by GPU. You might need to turn on `Hardware-Accelerated GPU Scheduling`. Go to Settings > Graphics > Turn on. More detail can be found in this [link here](https://www.howtogeek.com/756935/how-to-enable-hardware-accelerated-gpu-scheduling-in-windows-11/)\n",
    "![Demo image](https://www.howtogeek.com/wp-content/uploads/2021/09/Toggle-on-to-enable-hardware-accelerated-gpu-scheduling-on-your-pc.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f573ba",
   "metadata": {},
   "source": [
    "## Turn off GPU\n",
    "\n",
    "In case you want to turn off GPU acceleration, here are choices.\n",
    "\n",
    "```python\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "```\n",
    "\n",
    "Or\n",
    "\n",
    "```python\n",
    "try:\n",
    "    # Disable all GPUS\n",
    "    tf.config.set_visible_devices([], 'GPU')\n",
    "    visible_devices = tf.config.get_visible_devices()\n",
    "    for device in visible_devices:\n",
    "        assert device.device_type != 'GPU'\n",
    "except:\n",
    "    # Invalid device or cannot modify virtual devices once initialized.\n",
    "    pass\n",
    "```\n",
    "\n",
    "[Source](https://datascience.stackexchange.com/questions/58845/how-to-disable-gpu-with-tensorflow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d9e437",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b198e55c",
   "metadata": {},
   "source": [
    "## Parallelism \n",
    "\n",
    "We can get/set number of threads used for parallelism between independent operations `get_inter_op_parallelism_threads` or number of threads used within an individual op for parallelism `get_intra_op_parallelism_threads`.\n",
    "\n",
    "A value of 0 means the system picks an appropriate number.\n",
    "```python\n",
    "tf.config.threading.set_inter_op_parallelism_threads(4)\n",
    "tf.config.threading.set_intra_op_parallelism_threads(16)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c62fa40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.threading.get_inter_op_parallelism_threads()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b613772a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'disable_model_pruning': False, 'disable_meta_optimizer': False}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.optimizer.get_experimental_options()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9e6c2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
