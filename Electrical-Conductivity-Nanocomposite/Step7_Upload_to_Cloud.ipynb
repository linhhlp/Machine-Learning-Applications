{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42eca9cf",
   "metadata": {},
   "source": [
    "# Upload to Cloud\n",
    "\n",
    "## Exporting to model and Deploying on Google Cloud Platform\n",
    "\n",
    "1. Export models\n",
    "2. Create a project on Google Cloud\n",
    "3. Create a Google Cloud Storage Bucket\n",
    "4. Create a model resource\n",
    "5. Test model web interface\n",
    "6. Run / Test locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0095174",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from   sklearn.model_selection import train_test_split\n",
    "from   sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "# Import this module's functions\n",
    "from functions import map_num_to_string, map_string_to_num, sparse_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62cb9268",
   "metadata": {},
   "source": [
    "## Load saved data\n",
    "\n",
    "Loading saved model and scalers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdd4698d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pickle import load\n",
    "\n",
    "# Load model\n",
    "model = tf.keras.models.load_model('saved/predictor-conductivity-model')\n",
    "\n",
    "# Load scalers\n",
    "X_scaler = load(open('saved/X_scaler.pkl', 'rb'))\n",
    "Y_scaler = load(open('saved/Y_scaler.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6afb7521",
   "metadata": {},
   "source": [
    "## Export model for deploying\n",
    "\n",
    "Exported models could be a TensorFlow SavedModel\n",
    "\n",
    "[Export custom pipeline code](https://cloud.google.com/ai-platform/prediction/docs/exporting-for-prediction#custom-pipeline-code): If you need your custom code and functions.\n",
    "\n",
    "More information on [tensorflow.org](https://www.tensorflow.org/guide/saved_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91232b1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: deploy_cloud/assets\n"
     ]
    }
   ],
   "source": [
    "tf.saved_model.save(model, 'deploy_cloud/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b97fe3",
   "metadata": {},
   "source": [
    "## Create a project on Google Cloud \n",
    "\n",
    "To start working with GCP, We need a new project to deploy the model. \n",
    "\n",
    "This project named `Nanocomposite Conductivity` with ID `nanocomposite-conductivity` on GCP."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a29a56",
   "metadata": {},
   "source": [
    "## Create a Google Cloud Storage Bucket\n",
    "\n",
    "The model (saved) files must be uploaded to cloud storage provided by Google.\n",
    "\n",
    "To ease process, you WEB interface at [console.cloud.google.com](https://console.cloud.google.com/storage/)\n",
    "\n",
    "The new bucket was created with path is `electrical-conductivity-nanocomposite/deploy_cloud`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335d7ac3",
   "metadata": {},
   "source": [
    "## Create a model resource\n",
    "\n",
    "Open [ai-platform](https://console.cloud.google.com/ai-platform/models) Website. You might need to enable API first.\n",
    "\n",
    "Then create a model. This project name model `electrical_conductivity_nanocomposite`.\n",
    "\n",
    "Next, a version must be created.\n",
    "\n",
    "We can choose Pre-built container which supports TensorFlow.\n",
    "\n",
    "Browse Model URI to where model was uploaded on Bucket.\n",
    "\n",
    "You can optionally add GPUs to accelerate each prediction node GPUs which incur additional costs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33b6386",
   "metadata": {},
   "source": [
    "## Test model  web interface\n",
    "\n",
    "We can quickly test the model at console.cloud.google.com once the version is created. Note that the creation of version (step above) takes (long) time to finish.\n",
    "\n",
    "Try this input (X features were already scaled):\n",
    "```python\n",
    "{\"instances\":[ [1.0, 0.5, 0.10409017] ]}\n",
    "```\n",
    "\n",
    "We should expect $-0.778929830$ as local deploy predicted. In my test case, it works smoothly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b875d07f",
   "metadata": {},
   "source": [
    "## Run / Test locally\n",
    "\n",
    "To run the model remotely, we need to set right permission to access to model online. \n",
    "\n",
    "To set up authentication, you need to create a service account key and set an environment variable for the file path to the service account key.\n",
    "\n",
    "1. Create a service account [console.cloud.google.com](https://console.cloud.google.com/projectselector/iam-admin/serviceaccounts/create?supportedpurview=project)\n",
    "\n",
    "__role field__: select AI Platform > `AI Platform Admin` and Storage > `Storage Object Admin`\n",
    "\n",
    "2. Create a service account key for authentication\n",
    "\n",
    "Create `A JSON` key file and download to your computer. Rename to `credentials.json` if wanted.\n",
    "\n",
    "3. Sample code\n",
    "Below is the sample code tested on my local machine successfully. In other computers, you might need package dependencies such as `oauth2client`, `googleapiclient`, `google.api_core`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d92d11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import googleapiclient.discovery\n",
    "from google.api_core.client_options import ClientOptions\n",
    "from oauth2client.client import GoogleCredentials\n",
    "\n",
    "\n",
    "def predict_json(\n",
    "    project, model, instances, CREDENTIALS_FILE, region, version=None\n",
    "):\n",
    "    \"\"\"Send json data to a deployed model for prediction.\n",
    "\n",
    "    Args:\n",
    "        project (str): project where the Cloud ML Engine Model is deployed.\n",
    "        region (str): regional endpoint; set to None for ml.googleapis.com\n",
    "        model (str): model name.\n",
    "        instances ([Mapping[str: Any]]): Keys should be the names of Tensors\n",
    "            your deployed model expects as inputs. Values should be datatypes\n",
    "            convertible to Tensors, or (potentially nested) lists of datatypes\n",
    "            convertible to tensors.\n",
    "        version: str, version of the model to target.\n",
    "    Returns:\n",
    "        Mapping[str: any]: dictionary of prediction results defined by the\n",
    "            model.\n",
    "    \"\"\"\n",
    "    # Create the ML Engine service object.\n",
    "    # To authenticate set the environment variable\n",
    "    # GOOGLE_APPLICATION_CREDENTIALS=<path_to_service_account_file>\n",
    "    credentials = GoogleCredentials.from_stream(CREDENTIALS_FILE)\n",
    "    prefix = \"{}-ml\".format(region) if region else \"ml\"\n",
    "    api_endpoint = \"https://{}.googleapis.com\".format(prefix)\n",
    "    client_options = ClientOptions(api_endpoint=api_endpoint)\n",
    "    service = googleapiclient.discovery.build(\n",
    "        \"ml\", \"v1\", client_options=client_options, credentials=credentials\n",
    "    )\n",
    "    name = \"projects/{}/models/{}\".format(project, model)\n",
    "\n",
    "    if version is not None:\n",
    "        name += \"/versions/{}\".format(version)\n",
    "\n",
    "    response = (\n",
    "        service.projects()\n",
    "        .predict(name=name, body={\"instances\": instances})\n",
    "        .execute()\n",
    "    )\n",
    "\n",
    "    if \"error\" in response:\n",
    "        raise RuntimeError(response[\"error\"])\n",
    "\n",
    "    return response[\"predictions\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82d8c163",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[-0.77892983]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CREDENTIALS_FILE = \"credentials.json\"\n",
    "PROJECT_ID = \"nanocomposite-conductivity\"\n",
    "MODEL_NAME = \"electrical_conductivity_nanocomposite\"\n",
    "# These are the values we want a prediction for\n",
    "inputs_for_prediction = [[1.0, 0.5, 0.10409017]]\n",
    "\n",
    "predict_json(\n",
    "    PROJECT_ID,\n",
    "    MODEL_NAME,\n",
    "    inputs_for_prediction,\n",
    "    CREDENTIALS_FILE,\n",
    "    \"us-central1\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d80260",
   "metadata": {},
   "source": [
    "## Installing dependencies\n",
    "\n",
    "`oauth2client` \n",
    "```python\n",
    "conda install oauth2client \n",
    "```\n",
    "\n",
    "`googleapiclient`\n",
    "```python\n",
    "conda install google-api-python-client \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9905a15",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "## Results are consistent\n",
    "\n",
    "The predictions from local computer, remote code, and web interface show a consistency of values. \n",
    "\n",
    "## Future Work\n",
    "\n",
    "Build app/web GUI online to host predictor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4f2fa6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
